{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main code\n",
    "\n",
    "At some points we could not make the rdd.map function work so we switched to regular map. Unfortunately then we don't really use pyspark's efficiency but at least we can answer the research questions\n",
    "\n",
    "\n",
    "#### HDFS\n",
    "Could be used using: \n",
    "\n",
    "data = sc.textFile('hdfs://scomp1334:9000/user/steen176/csv/butterflies.csv')\n",
    "\n",
    "\n",
    "#### addPyFile\n",
    "Adds the classes to store species and observations to the workers\n",
    "\n",
    "sc.addPyFile(\"classes.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from classes import Species, Observation\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    global species\n",
    "    sc.addPyFile(\"classes.py\")\n",
    "\n",
    "    data = sc.textFile(\"/home/WUR/steen176/birdsandbutterflies/test.dat\")\n",
    "    corrected = data.map(lambda line: correctLine(line))\n",
    "    species = extractSpecies(corrected)\n",
    "    \n",
    "    \n",
    "    #rdd.map did not work here\n",
    "    map(getObservation, corrected.toLocalIterator())\n",
    " \n",
    "    \n",
    "    #rdd.map did not work here\n",
    "    clusters = map(cluster, species.keys())\n",
    "    \n",
    "    #GetList of rare species\n",
    "    top = 1\n",
    "    rare_specs =  sorted([(specie, len(species[specie].observations)) for specie in species.keys()], \n",
    "                         key = lambda x: x[1])[0:top]\n",
    "    print (1,2,4) == (1,2,4)\n",
    "    \n",
    "    #try for rarest\n",
    "    rarest_name = rare_specs[0][0]\n",
    "    rarest_cluster = cluster(rarest_name).clusterCenters\n",
    "    rarest = (rarest_name, cluster(rarest_name).clusterCenters)\n",
    "    filtered_clusters = [x.clusterCenters for x in clusters \n",
    "                         if len(set(tuple([tuple(y.tolist()) for y in x.clusterCenters])) & set(tuple([tuple(y.tolist()) for y in rarest_cluster])))\n",
    "                         == len(rarest_cluster)]\n",
    "    print(filtered_clusters)\n",
    "    #findCombinations(rarest, filtered_clusters)\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getSpecies(line):\n",
    "    line = line.split(',')\n",
    "    return line[0]\n",
    "\n",
    "def correctLine(line):\n",
    "    line = line.split(',')\n",
    "    if len(line) != 10:\n",
    "        return ','.join(line[0:4] + [\" \".join(line[4:6])]+ line[6:])\n",
    "    else:\n",
    "        return ','.join(line)\n",
    "\n",
    "def getObservation(line):\n",
    "    line = line.split(',')\n",
    "    specie = line[0]\n",
    "    for i in xrange(int(line[5])):\n",
    "        longti = line[8]\n",
    "        lati = line[9]\n",
    "        obs = Observation(longti,lati)\n",
    "        species[specie].addObservation(obs)\n",
    "    \n",
    "    \n",
    "def createSpecieObjects(species_list):\n",
    "    species_objects = {}\n",
    "    for specie in species_list:\n",
    "        obj = Species(specie)\n",
    "        species_objects[specie] = obj\n",
    "    return species_objects\n",
    "\n",
    "\n",
    "def extractSpecies(rdd):\n",
    "    species = rdd.map(getSpecies)\n",
    "    species_list  = list(set([x for x in species.toLocalIterator()]))\n",
    "    return createSpecieObjects(species_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from math import sqrt\n",
    "NUM_CLUSTER = 4\n",
    "\n",
    "def kmeans(sparse_vectors):\n",
    "    #sparsevectors should be a rdd containing sparsevectors\n",
    "    return KMeans.train(sparse_vectors, NUM_CLUSTER, maxIterations=20, runs=100, initializationMode=\"random\")\n",
    "\n",
    "def cluster(specie):\n",
    "    \n",
    "    vectors = species[specie].getVectorRDD()\n",
    "    return kmeans(sc.parallelize(vectors))\n",
    "\n",
    "\n",
    "    \n",
    "def error(point):\n",
    "    center = clusters.centers[clusters.predict(point)]\n",
    "    denseCenter = DenseVector(numpy.ndarray.tolist(center))\n",
    "    return sqrt(sum([x**2 for x in (DenseVector(point.toArray()) - denseCenter)]))\n",
    "\n",
    "    WSSSE = parsedData.map(lambda point: error(point)).reduce(lambda x, y: x + y)\n",
    "    print(WSSSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy \n",
    "def centerdiffs(centers, DIFF=0.1):\n",
    "    centerA = centers[0]\n",
    "    centerB = centers[1]\n",
    "    \n",
    "    longA = centerA[0]\n",
    "    longB = centerB[0]\n",
    "    lattA = centerA[1]\n",
    "    lattB = centerB[1]\n",
    "    \n",
    "    longDiff = numpy.subtract(longA, longB)\n",
    "    lattDiff = numpy.subtract(lattA, lattB)\n",
    "    \n",
    "    if longDiff < DIFF and lattDiff < DIFF:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "\n",
    "def findCombinations(rare_specie, all_species_centers):\n",
    "    \"\"\"Compare a rare specie with all other species and see if some clusters overlap.\n",
    "    \n",
    "        Keyword Arguments:\n",
    "            rare_specie_centers -- The np.array of cluster centers\n",
    "                    format: (u'Cuculus canorus', Array())\n",
    "            all_species_centers -- The np.array of cluster centers for all other species\n",
    "        Returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "    rare_centers = rare_specie[1]\n",
    "    for one in all_species_centers:\n",
    "        for center in rare_centers:\n",
    "            for one_center in one:\n",
    "                if centerdiffs((center, one_center)):\n",
    "                    #pass\n",
    "                    print \"yes\"\n",
    "                else:\n",
    "                    #pass\n",
    "                    print \"no\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pyspark.mllib.linalg import SparseVector\n",
    "\n",
    "class Species():\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.observations = []\n",
    "\n",
    "    def addObservation(self, observ):\n",
    "        self.observations.append(observ)\n",
    "\n",
    "    def getVectorRDD(self):\n",
    "        return [x.toSparseVector() for x in self.observations]\n",
    "\n",
    "class Observation():\n",
    "    def __init__(self,longti, lati):\n",
    "        self.longti = longti\n",
    "        self.lati = lati\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"observatio\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"observation\"\n",
    "\n",
    "    def toSparseVector(self):\n",
    "        return SparseVector(2, [[0, self.longti], [1, self.lati]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
