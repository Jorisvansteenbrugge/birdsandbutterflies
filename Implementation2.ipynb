{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "from classes import Species, Observation\n",
    "#sc.addPyFile(\"classes.py\")\n",
    "\n",
    "def createSpecieObjects(species_list):\n",
    "    species_objects = {}\n",
    "    for specie in species_list:\n",
    "        obj = Species(specie)\n",
    "        species_objects[specie] = obj\n",
    "    return species_objects\n",
    "\n",
    "\n",
    "def extractSpecies(rdd):\n",
    "    species = rdd.map(getSpecies)\n",
    "    species_list  = list(set([x for x in species.toLocalIterator()]))\n",
    "    return createSpecieObjects(species_list)\n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    global species\n",
    "    data = sc.textFile('hdfs://scomp1334:9000/user/steen176/csv/smalltest.dat')\n",
    "\n",
    "    #Somtimes there was a comma in a line in a description and therefore \n",
    "    # there would be an index to many when splitting\n",
    "    corrected = data.map(lambda line: correctLine(line))\n",
    "    species = extractSpecies(corrected)\n",
    "    \n",
    "    #res = corrected.map(lambda line: getObservation(line))\n",
    "    #rdd.map did not work here\n",
    "    map(getObservation, corrected.toLocalIterator())\n",
    "    \n",
    "    to_cluster = sc.parallelize(species[\"Pernis apivorus\"].observations)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
