{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main code\n",
    "\n",
    "At some points we could not make the rdd.map function work so we switched to regular map. Unfortunately then we don't really use pyspark's efficiency but at least we can answer the research questions.\n",
    "\n",
    "\n",
    "#### HDFS\n",
    "Could be used using: \n",
    "\n",
    "data = sc.textFile('hdfs://scomp1334:9000/user/steen176/csv/butterflies.csv')\n",
    "\n",
    "\n",
    "#### addPyFile\n",
    "Adds the classes to store species and observations to the workers\n",
    "\n",
    "sc.addPyFile(\"classes.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from classes import Species, Observation\n",
    "import subprocess as sp\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    global species\n",
    "    sc.addPyFile(\"classes.py\")\n",
    "\n",
    "    data = sc.textFile(\"/home/WUR/steen176/Downloads/butterflies.csv\")\n",
    "    corrected = data.map(lambda line: correctLine(line))\n",
    "    species = extractSpecies(corrected)\n",
    "    \n",
    "    \n",
    "    #rdd.map did not work here\n",
    "    map(getObservation, corrected.toLocalIterator())\n",
    "    \n",
    "    #rdd.map did not work here\n",
    "    clusters = map(cluster, species.keys())\n",
    "    \n",
    "    #GetList of rare species\n",
    "    top = 1\n",
    "    rare_specs =  sorted([(specie, len(species[specie].observations)) for specie in species.keys()], \n",
    "                         key = lambda x: x[1])[0:top]\n",
    "    \n",
    "    \n",
    "    #currently only for the rarest specie\n",
    "    rarest_name = rare_specs[0][0]\n",
    "    rarest_cluster = cluster(rarest_name)[1].clusterCenters\n",
    "    rarest = (rarest_name, cluster(rarest_name)[1].clusterCenters)\n",
    "    \n",
    "    filtered_clusters = [(x[0], [x[1].clusterCenters]) for x in clusters if \n",
    "                       [tuple(y.tolist()) for y in x[1].clusterCenters] != \n",
    "                       [tuple(y.tolist()) for y in rarest_cluster]\n",
    "                        ]\n",
    "   \n",
    "    \n",
    "    \n",
    "    #output\n",
    "    with open(\"out.tsv\", \"w\") as out_file:\n",
    "        for x in findCombinations(rarest, filtered_clusters):\n",
    "            out_file.write(x)\n",
    "            \n",
    "    \n",
    "    sp.call(\"echo 'rare_species\\tclusters_with\\tlongtitude\\tlattitude' > output.tsv; sort -u out.tsv >> output.tsv\", shell = True)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getSpecies(line):\n",
    "    line = line.split(',')\n",
    "    return line[0]\n",
    "\n",
    "def correctLine(line):\n",
    "    line = line.split(',')\n",
    "    if len(line) != 10:\n",
    "        return ','.join(line[0:4] + [\" \".join(line[4:6])]+ line[6:])\n",
    "    else:\n",
    "        return ','.join(line)\n",
    "\n",
    "def getObservation(line):\n",
    "    line = line.split(',')\n",
    "    specie = line[0]\n",
    "    for i in xrange(int(line[5])):\n",
    "        longti = line[8]\n",
    "        lati = line[9]\n",
    "        obs = Observation(longti,lati)\n",
    "        species[specie].addObservation(obs)\n",
    "    \n",
    "    \n",
    "def createSpecieObjects(species_list):\n",
    "    species_objects = {}\n",
    "    for specie in species_list:\n",
    "        obj = Species(specie)\n",
    "        species_objects[specie] = obj\n",
    "    return species_objects\n",
    "\n",
    "\n",
    "def extractSpecies(rdd):\n",
    "    species = rdd.map(getSpecies)\n",
    "    species_list  = list(set([x for x in species.toLocalIterator()]))\n",
    "    return createSpecieObjects(species_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from math import sqrt\n",
    "NUM_CLUSTER = 4\n",
    "\n",
    "def kmeans(sparse_vectors):\n",
    "    #sparsevectors should be a rdd containing sparsevectors\n",
    "    return KMeans.train(sparse_vectors, NUM_CLUSTER, maxIterations=20, runs=100, initializationMode=\"random\")\n",
    "\n",
    "def cluster(specie):\n",
    "    \n",
    "    vectors = species[specie].getVectorRDD()\n",
    "    return (specie, kmeans(sc.parallelize(vectors)))\n",
    "\n",
    "\n",
    "    \n",
    "def error(point):\n",
    "    center = clusters.centers[clusters.predict(point)]\n",
    "    denseCenter = DenseVector(numpy.ndarray.tolist(center))\n",
    "    return sqrt(sum([x**2 for x in (DenseVector(point.toArray()) - denseCenter)]))\n",
    "\n",
    "    WSSSE = parsedData.map(lambda point: error(point)).reduce(lambda x, y: x + y)\n",
    "    print(WSSSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy \n",
    "def centerdiffs(centerA, centerB, DIFF=0.1):\n",
    "\n",
    "    \n",
    "    longA = centerA[0]\n",
    "    longB = centerB[0]\n",
    "    lattA = centerA[1]\n",
    "    lattB = centerB[1]\n",
    "    \n",
    "    longDiff = numpy.subtract(longA, longB)\n",
    "    lattDiff = numpy.subtract(lattA, lattB)\n",
    "    \n",
    "    #print(\"Longdiff: {}\\t\\tLattdiff: {}\".format(str(longDiff), str(lattDiff)))\n",
    "\n",
    "    if (longDiff < DIFF and longDiff > DIFF*-1) and (lattDiff < DIFF and lattDiff > DIFF*-1):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "\n",
    "def findCombinations(rare_specie, all_species_centers):\n",
    "    \"\"\"Compare a rare specie with all other species and see if some clusters overlap.\n",
    "    \n",
    "        Keyword Arguments:\n",
    "            rare_specie_centers -- The np.array of cluster centers\n",
    "                    format: (u'Cuculus canorus', Array())\n",
    "            all_species_centers -- The np.array of cluster centers for all other species\n",
    "        Returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "    rare_name = rare_specie[0]\n",
    "    rare_centers = rare_specie[1]\n",
    "    for one in all_species_centers:\n",
    "        other_name = one[0]\n",
    "        for center in rare_centers:\n",
    "            for one_center in one[1][0]:\n",
    "                #print(\"Center: {}\\t\\t Onecenter: {}\".format(center, one_center))\n",
    "                if centerdiffs(center, one_center):\n",
    "                    yield \"{}\\t{}\\t{}\\t{}\\n\".format(rare_name, other_name, str(center[0]), str(center[1]))\n",
    "                else:\n",
    "                    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
